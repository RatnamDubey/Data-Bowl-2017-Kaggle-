{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dicom\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "from scipy.stats import gmean\n",
    "\n",
    "IMG_SIZE_PX = 50\n",
    "SLICE_COUNT = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Visualization\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "IMG_PX_SIZE = 28\n",
    "\n",
    "slicePatient = []\n",
    "count = 0\n",
    "\n",
    "sampleLabels = []\n",
    "sample_dir = 'C:/Users/parth/Desktop/PA/Bowl17/Data/sample_images/'\n",
    "\n",
    "\n",
    "for num,patient in enumerate(patients[:]):\n",
    "    label = labels_df.get_value(patient,'cancer')\n",
    "    path = sample_dir + patient\n",
    "    slices = [dicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
    "    slices.sort(key=lambda x:int(x.ImagePositionPatient[2]))\n",
    "    \n",
    "    sampleLabels = sampleLabels + [label] * (len(slices))\n",
    "    #sliceLen = sliceLen+len(slices)\n",
    "    slicePatient = slicePatient + slices\n",
    "\n",
    "    \n",
    "fig = plt.figure()\n",
    "for num,each_slice in enumerate(slices[:20]):\n",
    "    y= fig.add_subplot(4,5,num+1)\n",
    "    new_image = cv2.resize(np.array(each_slice.pixel_array),(IMG_PX_SIZE,IMG_PX_SIZE))\n",
    "    y.imshow(new_image)\n",
    "\n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "        \n",
    "\n",
    "def mean(a):\n",
    "    return sum(a) / len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(patient,filedir,lab_df,img_px_size=IMG_SIZE_PX, hm_slices=20, visualize=False):\n",
    "    ##print('Inside process')\n",
    "    \n",
    "    label = lab_df.get_value(patient, 'cancer')\n",
    "    path = filedir + patient\n",
    "    ##print(path)\n",
    "    slices = [dicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
    "    slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n",
    "\n",
    "    new_slices = []\n",
    "    slices = [cv2.resize(np.array(each_slice.pixel_array),(img_px_size,img_px_size)) for each_slice in slices]\n",
    "    \n",
    "    chunk_sizes = math.ceil(len(slices) / hm_slices)\n",
    "    for slice_chunk in chunks(slices, chunk_sizes):\n",
    "        slice_chunk = list(map(mean, zip(*slice_chunk)))\n",
    "        new_slices.append(slice_chunk)\n",
    "\n",
    "    if len(new_slices) == hm_slices-1:\n",
    "        new_slices.append(new_slices[-1])\n",
    "\n",
    "    if len(new_slices) == hm_slices-2:\n",
    "        new_slices.append(new_slices[-1])\n",
    "        new_slices.append(new_slices[-1])\n",
    "\n",
    "    if len(new_slices) == hm_slices+2:\n",
    "        new_val = list(map(mean, zip(*[new_slices[hm_slices-1],new_slices[hm_slices],])))\n",
    "        del new_slices[hm_slices]\n",
    "        new_slices[hm_slices-1] = new_val\n",
    "        \n",
    "    if len(new_slices) == hm_slices+1:\n",
    "        new_val = list(map(mean, zip(*[new_slices[hm_slices-1],new_slices[hm_slices],])))\n",
    "        del new_slices[hm_slices]\n",
    "        new_slices[hm_slices-1] = new_val\n",
    "\n",
    "    if visualize:\n",
    "        fig = plt.figure()\n",
    "        for num,each_slice in enumerate(new_slices):\n",
    "            y = fig.add_subplot(4,5,num+1)\n",
    "            y.imshow(each_slice, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    if label == 1: label=np.array([0,1])\n",
    "    elif label == 0: label=np.array([1,0])\n",
    "        \n",
    "    return np.array(new_slices),label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nstage1_dir = 'C:/Users/parth/Desktop/PA/Bowl17/Data/stage1/'\\npatients = os.listdir(stage1_dir)\\nstage1_df = pd.read_csv('C:/Users/parth/Desktop/PA/Bowl17/Data/stage1_labels_new.csv', index_col=0)\\n\\nstage1_data = []\\nfor num,patient in enumerate(patients):\\n    if num % 100 == 0:\\n        print(num)\\n    try:\\n        img_data,label = process_data(patient,stage1_dir,stage1_df,img_px_size=IMG_SIZE_PX, hm_slices=SLICE_COUNT)\\n        #print(img_data.shape,label)\\n        stage1_data.append([img_data,label])\\n    except KeyError as e:\\n        print('This is unlabeled data!')\\n\\nnp.save('stage1data-{}-{}-{}.npy'.format(IMG_SIZE_PX,IMG_SIZE_PX,SLICE_COUNT), stage1_data)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Run Just Once and read from Hard Disk\n",
    "\n",
    "stage1_dir = 'C:/Users/parth/Desktop/PA/Bowl17/Data/stage1/'\n",
    "patients = os.listdir(stage1_dir)\n",
    "stage1_df = pd.read_csv('C:/Users/parth/Desktop/PA/Bowl17/Data/stage1_labels_new.csv', index_col=0)\n",
    "\n",
    "stage1_data = []\n",
    "for num,patient in enumerate(patients):\n",
    "    if num % 100 == 0:\n",
    "        print(num)\n",
    "    try:\n",
    "        img_data,label = process_data(patient,stage1_dir,stage1_df,img_px_size=IMG_SIZE_PX, hm_slices=SLICE_COUNT)\n",
    "        #print(img_data.shape,label)\n",
    "        stage1_data.append([img_data,label])\n",
    "    except KeyError as e:\n",
    "        print('This is unlabeled data!')\n",
    "\n",
    "np.save('stage1data-{}-{}-{}.npy'.format(IMG_SIZE_PX,IMG_SIZE_PX,SLICE_COUNT), stage1_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1595, 2)\n",
      "(1595, 50, 50)\n",
      "(1595, 2500)\n",
      "(1595,)\n"
     ]
    }
   ],
   "source": [
    "stage1_data = np.load('stage1data-50-50-20.npy')\n",
    "\n",
    "train_data = stage1_data[:]\n",
    "print(train_data.shape)\n",
    "\n",
    "train_features = []\n",
    "train_labels = []\n",
    "\n",
    "\n",
    "for i in range(0,train_data.shape[0]):\n",
    "    train_features = train_features + [(train_data[i,0])[0]]\n",
    "    train_labels = train_labels + [(train_data[i,1])[1]]\n",
    "'''\n",
    "for i in range(0,len(train_features)):\n",
    "    for j in range(0,len(train_features[i])):\n",
    "        for k in range(0,len((train_features[i])[j])):\n",
    "                       if ((train_features[i])[j])[k] == -2000:\n",
    "                           ((train_features[i])[j])[k] = 0\n",
    "'''    \n",
    "train_features = np.array(train_features)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "nsamples, nx, ny = train_features.shape\n",
    "d2_train_features = train_features.reshape((nsamples,nx*ny))\n",
    "'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(d2_train_features)\n",
    "d2_train_features = scaler.transform(d2_train_features)\n",
    "'''\n",
    "print(train_features.shape)\n",
    "print(d2_train_features.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "del train_data\n",
    "del stage1_data\n",
    "del train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nstage2_dir = 'C:/Users/parth/Desktop/PA/Bowl17/Data/stage2/'\\npatients = os.listdir(stage2_dir)\\nstage2_df = pd.read_csv('C:/Users/parth/Desktop/PA/Bowl17/Data/stage2_sample_submission.csv', index_col=0)\\n\\ntestPatients_df = pd.read_csv('C:/Users/parth/Desktop/PA/Bowl17/Data/stage2_sample_submission.csv')\\ntestPatientsList = testPatients_df['id'].tolist()\\n\\nstage2_data = []\\nfor num,patient in enumerate(testPatientsList):\\n    if num % 100 == 0:\\n        print(num)\\n    try:\\n        img_data,label = process_data(patient,stage2_dir,stage2_df,img_px_size=IMG_SIZE_PX, hm_slices=SLICE_COUNT)\\n        ##print(str(num) + '    Back to try')\\n        stage2_data.append([img_data,label])\\n    except KeyError as e:\\n        print('This is unlabeled data!')\\n\\nnp.save('stage2data-{}-{}-{}.npy'.format(IMG_SIZE_PX,IMG_SIZE_PX,SLICE_COUNT), stage2_data)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Run Just Once and read from Hard Disk\n",
    "\n",
    "stage2_dir = 'C:/Users/parth/Desktop/PA/Bowl17/Data/stage2/'\n",
    "patients = os.listdir(stage2_dir)\n",
    "stage2_df = pd.read_csv('C:/Users/parth/Desktop/PA/Bowl17/Data/stage2_sample_submission.csv', index_col=0)\n",
    "\n",
    "testPatients_df = pd.read_csv('C:/Users/parth/Desktop/PA/Bowl17/Data/stage2_sample_submission.csv')\n",
    "testPatientsList = testPatients_df['id'].tolist()\n",
    "\n",
    "stage2_data = []\n",
    "for num,patient in enumerate(testPatientsList):\n",
    "    if num % 100 == 0:\n",
    "        print(num)\n",
    "    try:\n",
    "        img_data,label = process_data(patient,stage2_dir,stage2_df,img_px_size=IMG_SIZE_PX, hm_slices=SLICE_COUNT)\n",
    "        ##print(str(num) + '    Back to try')\n",
    "        stage2_data.append([img_data,label])\n",
    "    except KeyError as e:\n",
    "        print('This is unlabeled data!')\n",
    "\n",
    "np.save('stage2data-{}-{}-{}.npy'.format(IMG_SIZE_PX,IMG_SIZE_PX,SLICE_COUNT), stage2_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data\n",
      "(506, 2)\n",
      "Test Data\n",
      "(506, 50, 50)\n",
      "(506, 2500)\n"
     ]
    }
   ],
   "source": [
    "stage2_data = np.load('stage2data-50-50-20.npy')\n",
    "\n",
    "print('Test Data')\n",
    "test_data = stage2_data[:]\n",
    "print(test_data.shape)\n",
    "\n",
    "test_features = []\n",
    "\n",
    "for i in range(0,test_data.shape[0]):\n",
    "    test_features = test_features + [(test_data[i,0])[0]]\n",
    "'''\n",
    "for i in range(0,len(test_features)):\n",
    "    for j in range(0,len(test_features[i])):\n",
    "        for k in range(0,len((test_features[i])[j])):\n",
    "                       if ((test_features[i])[j])[k] == -2000:\n",
    "                           ((test_features[i])[j])[k] = 0    \n",
    "'''    \n",
    "test_features = np.array(test_features)\n",
    "nsamples, nx, ny = test_features.shape\n",
    "d2_test_features = test_features.reshape((nsamples,nx*ny))\n",
    "'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(d2_test_features)\n",
    "d2_test_features = scaler.transform(d2_test_features)\n",
    "'''\n",
    "print('Test Data')\n",
    "print(test_features.shape)\n",
    "print(d2_test_features.shape)\n",
    "\n",
    "del stage2_data\n",
    "del test_data\n",
    "del test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parth\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\parth\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "#Set the tuning parameter\n",
    "params = {'C':[1000,1200,1400], 'tol': [0.00001]}\n",
    "\n",
    "##Create the Logistic Regression model\n",
    "logreg = LogisticRegression(solver='newton-cg', multi_class='multinomial')\n",
    "##Use the Grid Search with the params\n",
    "clf = GridSearchCV(logreg,params, scoring='log_loss', refit='True', n_jobs=-1, cv=5)\n",
    "##Fit the models\n",
    "clf_fit = clf.fit(d2_train_features,train_labels)\n",
    "\n",
    "test_pred_labels= clf.predict(d2_test_features)\n",
    "\n",
    "test_pred_labProb = clf.predict_proba(d2_test_features)\n",
    "pred = []\n",
    "for i in range(0,test_pred_labProb.shape[0]):\n",
    "    pred = pred + [test_pred_labProb[i,1]]\n",
    "#print(pred)\n",
    "'''\n",
    "test_pred_logProb = clf.predict_log_proba(d2_test_features)\n",
    "pred = []\n",
    "for i in range(0,test_pred_logProb.shape[0]):\n",
    "    pred = pred + [test_pred_logProb[i,1]]\n",
    "'''\n",
    "logisticPatients_df = pd.read_csv('C:/Users/parth/Desktop/PA/Bowl17/Data/stage2_sample_submission.csv')\n",
    "logisticPatients_df['cancer'] = pd.Series(pred)\n",
    "logisticPatients_df.to_csv(\"C:/Users/parth/Desktop/PA/Bowl17/Data/stage2_pred_log_final.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_my_xgb():\n",
    "    df = pd.read_csv('C:/Users/parth/Desktop/PA/Bowl17/Data/stage1_labels_new.csv')\n",
    "\n",
    "    x = d2_train_features##np.load('stage1data-50-50-20.npy')\n",
    "    y = train_labels\n",
    "\n",
    "    clfs = []\n",
    "    for seed in range(15):\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=10, random_state=14+seed, shuffle=True)\n",
    "    \n",
    "        \n",
    "        '''\n",
    "        for train_index, test_index in skf.split(x, y):\n",
    "            trn_x, val_x = x[train_index,:], x[test_index,:]\n",
    "            trn_y, val_y = y[train_index], y[test_index]\n",
    "        '''\n",
    "        clf = xgb.XGBRegressor(max_depth=11,\n",
    "                               n_estimators=1500,\n",
    "                               min_child_weight=9,\n",
    "                               learning_rate=0.03,\n",
    "                               nthread=8,\n",
    "                               subsample=0.80,\n",
    "                               colsample_bytree=0.80,\n",
    "                               seed=88+seed)\n",
    "\n",
    "        clf.fit(d2_train_features, train_labels)\n",
    "        clfs.append(clf)\n",
    "\n",
    "    return clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 id    cancer\n",
      "0  004828796b994741c4466f59a8c7e9a4  0.224903\n",
      "1  007c1246c5fe6f200378f6b91323dc2a  0.390215\n",
      "2  00f6c1bd02eb49e3d8dbfc7d957a709e  0.391744\n",
      "3  0171e54e4c0f68e8fc8c24523f71a86f  0.273023\n",
      "4  019cb268efb93de5446984242bac0380  0.354794\n"
     ]
    }
   ],
   "source": [
    "clfs = train_my_xgb()\n",
    "\n",
    "df = pd.read_csv('C:/Users/parth/Desktop/PA/Bowl17/Data/stage2_sample_submission.csv')\n",
    "\n",
    "x = d2_test_features\n",
    "preds = []\n",
    "for clf in clfs:\n",
    "    preds.append(np.clip(clf.predict(x),0.001,1))\n",
    "\n",
    "pred = gmean(np.array(preds), axis=0)\n",
    "df['cancer'] = pred\n",
    "df.to_csv('C:/Users/parth/Desktop/PA/Bowl17/Data/stage2_pred_xgb_final.csv', index=False)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
